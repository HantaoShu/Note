# Chapter 1 绪论
#### 1.2 基本术语
- 分类和回归的区别  分类是预测离散值 回归是预测连续值 
- 根据训练数据是否拥有标记信息 分为有监督和无监督  回归是前者代表 聚类是后者代表
- 通常假设每个样本都是独立同分布 iid

#### 1.3 假设空间
我们可以把学习过程看作一个在所有假设组成的空间中搜索的过程  
假设空间: 所有可能的假设组成的空间 即指所有搜索的可能 自顶向下  
版本空间: 与训练集一致的假设集合 搜索方法 

#### 1.4 归纳偏好
归纳偏好是指在选择模型的时候进行的选择  
奥卡姆剃刀法则: 若存在多个假设与观察一致 选择最简单的那一个  
没有免费的午餐定理(NFL): 在问题出现的机会相同或者所有问题同等重要下学习算法的期望性相同。   
告诉我们谈论算法必须针对问题

# Chapter 2 模型评估与选择
#### 2.1 经验误差与过拟合
- 训练误差(经验误差): 学习器在训练集上的误差  
- 泛华误差: 学习器在新样本上的误差  
- 欠拟合和过拟合 欠拟合比较容易客服 如在决策树中加扩展分支 在神经网络中增加训练轮数  过拟合无法避免 只能缓解

#### 2.2 评估方法
1. 留出法  
  将数据集分成两个互斥的集合  一个用于训练集S 一个为测试集T  
  分层采样 保证训练数据和测试数据中正例和反例比例相同  
  分隔合理 例如分隔时位置 对于某个参数  
  多次平均

2. 交叉验证法  
  将数据集分成k个大小相似的子集 每个子集尽量保证数据分布一致性 每次用k-1个子集的并进行训练 用剩下一个进程测验 那么可以测验k次 取这k次的平均  
  与此相关的 留一法 每次只取一个样本测验 只能用于样本数量不大的情况下

3. 自助法(bootstraping)
  每次从原样本随机挑选一个样本  持续m次即得到一个大小为m的样本 在m次取样中 有
  每次从原样本随机挑选一个样本  持续m次即得到一个大小为m的样本 在m次取样中 有36.8%的与样本不同 我们就可以将这m个样本做训练集 它和原样本的差集作为测试集合 

#### 2.3 性能度量
- 回归任务最常用的是均方误差   
- 查准率 precision 查全率 recall P = TP/(TP+FP)  R=TP/(TP+FN)   
  查准率和查全率通常是一对矛盾的度量  一者高时另外一个通常会低  
- PR曲线   
  若要比较两个学习器的能力 那么可以比较他们的面积   
  平衡点 BEP 当查准率=查全率的点  
- F1 和Fbeta  对查准率和查全率有不同的要求的时候用Fbeta  Fbeta=(1+beta^2)*P*R/((beta^2)*P+R)   
  当beta>1 时对查全率有更大的影响  当beta<1时对查准率有更大影响
- 若有多次训练 则可以得到一个二维混淆矩阵 那么可以得到平均的P和R 然后在利用平均的PR 得到平均的F1
- ROC和AUC  
  在对一个实数值进行预测的时候 通常会将其放在[0,1]中 如果大于某个阈值则为正例 那么就可以通过确定阈值进行确定 如果更重视差准 那么则放置较前  反之相同   
  ROC ROC曲线纵轴为TPR 真正例率 横轴为FPR 假正率  
  与PR曲线相同 面积越大则学习器越佳 面积叫AUC  
  形式化上AUC是确定预测的质量 定义loss = 1/(m<sup>+</sup>m<sup>-</sup>) (sum(is(f(x<sup>+</sup>)>f(x<sup>-</sup>)))+sum(is(f(x<sup>+</sup>)=f(x<sup>-</sup>)))/2)  AUC = 1-loss
- 非均等代价  
  由于有时候将正例判成负例和将负例判成正例说带来的代价不同，故可以将他们赋权值 赋权之后会得到新的错误率以及ROC曲线

#### 2.4 比较检验
机器学习重点比较检验大多为假设检验
- 二分检验 在机器学习中，判断错误的清空可以用二项分布模型 对应当可以用二项检验来判断在某个置信区间下 学习器的泛化错误情况
- 对同一个学习器的多次建业可以用t检验来判断泛化性能  利用t分布及计算得到的方差和均值 可以得到在一定置信区间下的泛化错误情况
- 交叉t检验
