# Chapter 1 绪论
#### 1.2 基本术语
- 分类和回归的区别  分类是预测离散值 回归是预测连续值 
- 根据训练数据是否拥有标记信息 分为有监督和无监督  回归是前者代表 聚类是后者代表
- 通常假设每个样本都是独立同分布 iid

#### 1.3 假设空间
我们可以把学习过程看作一个在所有假设组成的空间中搜索的过程  
假设空间: 所有可能的假设组成的空间 即指所有搜索的可能 自顶向下  
版本空间: 与训练集一致的假设集合 搜索方法 

#### 1.4 归纳偏好
归纳偏好是指在选择模型的时候进行的选择  
奥卡姆剃刀法则: 若存在多个假设与观察一致 选择最简单的那一个  
没有免费的午餐定理(NFL): 在问题出现的机会相同或者所有问题同等重要下学习算法的期望性相同。   
告诉我们谈论算法必须针对问题

# Chapter 2 模型评估与选择
#### 2.1 经验误差与过拟合
- 训练误差(经验误差): 学习器在训练集上的误差  
- 泛华误差: 学习器在新样本上的误差  
- 欠拟合和过拟合 欠拟合比较容易客服 如在决策树中加扩展分支 在神经网络中增加训练轮数  过拟合无法避免 只能缓解

#### 2.2 评估方法
1. 留出法  
  将数据集分成两个互斥的集合  一个用于训练集S 一个为测试集T  
  分层采样 保证训练数据和测试数据中正例和反例比例相同  
  分隔合理 例如分隔时位置 对于某个参数  
  多次平均

2. 交叉验证法  
  将数据集分成k个大小相似的子集 每个子集尽量保证数据分布一致性 每次用k-1个子集的并进行训练 用剩下一个进程测验 那么可以测验k次 取这k次的平均  
  与此相关的 留一法 每次只取一个样本测验 只能用于样本数量不大的情况下

3. 自助法(bootstraping)
  每次从原样本随机挑选一个样本  持续m次即得到一个大小为m的样本 在m次取样中 有
  每次从原样本随机挑选一个样本  持续m次即得到一个大小为m的样本 在m次取样中 有36.8%的与样本不同 我们就可以将这m个样本做训练集 它和原样本的差集作为测试集合 

#### 2.3 性能度量
- 回归任务最常用的是均方误差   
- 查准率 precision 查全率 recall P = TP/(TP+FP)  R=TP/(TP+FN)   
  查准率和查全率通常是一对矛盾的度量  一者高时另外一个通常会低  
- PR曲线   
  若要比较两个学习器的能力 那么可以比较他们的面积   
  平衡点 BEP 当查准率=查全率的点  
- F1 和Fbeta  对查准率和查全率有不同的要求的时候用Fbeta  Fbeta=(1+beta^2)*P*R/((beta^2)*P+R)   
  当beta>1 时对查全率有更大的影响  当beta<1时对查准率有更大影响
- 若有多次训练 则可以得到一个二维混淆矩阵 那么可以得到平均的P和R 然后在利用平均的PR 得到平均的F1
- ROC和AUC  
  在对一个实数值进行预测的时候 通常会将其放在[0,1]中 如果大于某个阈值则为正例 那么就可以通过确定阈值进行确定 如果更重视差准 那么则放置较前  反之相同   
  ROC ROC曲线纵轴为TPR 真正例率 横轴为FPR 假正率  
  与PR曲线相同 面积越大则学习器越佳 面积叫AUC  
  形式化上AUC是确定预测的质量 定义loss = 1/(m<sup>+</sup>m<sup>-</sup>) (sum(is(f(x<sup>+</sup>)>f(x<sup>-</sup>)))+sum(is(f(x<sup>+</sup>)=f(x<sup>-</sup>)))/2)  AUC = 1-loss
- 非均等代价  
  由于有时候将正例判成负例和将负例判成正例说带来的代价不同，故可以将他们赋权值 赋权之后会得到新的错误率以及ROC曲线

#### 2.4 比较检验
机器学习重点比较检验大多为假设检验
- 二分检验 在机器学习中，判断错误的清空可以用二项分布模型 对应当可以用二项检验来判断在某个置信区间下 学习器的泛化错误情况
- 对同一个学习器的多次建业可以用t检验来判断泛化性能  利用t分布及计算得到的方差和均值 可以得到在一定置信区间下的泛化错误情况
- 交叉t检验 针对两个学习器 对于两个学习器 我们主要要判断两个学习器的泛化学习能力是否有显著差异 我们用两个学习器的插值的绝对值当做变量 并判断他在k-1的自由度下的t分布   
  在这里有x折的概念  由于害怕实验训练集合有一定程度的重叠故错误率不独立 故引入了x折  x折代表每x次 需要计算这x次的方差
- NcNemar检验 同样是针对两个学习器 两个学习器对同一测试样例 可能有4种结果关于是否测试正确 其中一方错误另一方正确的概率应该是相同的 在这里这两个概率的差应该服从正态分布 均值为1 那么可以设计对应的卡方分布 根据卡方分布判断是否有显著差异
- Friedman检验和Nemenyi检验   
  Friedman检验是对多个学习器的检验  将他们的测试性能进行排序 若有相同的平分序值 得到一个序值表 之后得到平均序值  
  平均序值服从正态分布 均值为(k+1)/2 方差为(k^2-1)/12 可以设置卡方分布变量  
  也可以用F分布代替卡方分布 F = (N-1)*x/(N(k-1)*x^2) x代表卡方分布  他服从k-1 和(k-1)(N-1) 的F分布  
  这可以判断所有算法是否显著相同 若有不同则可以用Nemenyi进行后续检验  
  CD = q(k*(k+1)/(6N))^0.5  若两个算法的平均序值超过CD 那么可以拒绝两个算法性能相同这个假设
#### 2.5 偏差和方差
通过公司据算可以看到泛化误差是偏差 方差 噪声的和  
偏差和方差是相互冲突的一对量  偏差-方差窘境

# Chapter 3 线性模型
#### 3.2 线性回归
从另外一个角度看待线性回归  
通过向量化 求导 后得到 w = (X<sup>T</sup>X)<sup>-1</sup>X<sup>T</sup>y  
如果X<sup>T</sup>X 是满秩矩阵 那么有唯一的值 若不这户解出多个w 那么就需要引入正则化  
广义线性模型  在某个函数下进行线性回归

#### 3.3 对数几率回归
引入sigmod函数  y = 1/(1+e<sup>-z</sup>)  
主要使用了极大似然法  即求最小值 即导数为0的时候的beta 有两种方法 一种是梯度下降 一种是牛顿迭代

#### 3.4 线性判别分析 LDA
思想: 将数据投影到一条线上  同类的点应该尽可能近 异类的点应该尽可能远 那么就可以将需要预测的点投影到这条线上进行分析  
同类的要求是他们的协方差和尽可能小 异类的中心距离尽可能大  
之后就可以得到LDA的公式 J 我们所需要的也就是最大化J  
由于Sb 和Sw都为已知  且上下皆有W W<sup>T</sup>  可以将一个定成1 另外的用拉格朗日乘子法 奇异值分解求极值  
可以扩展到多个类别 

#### 3.5 多分类学习
多分类需要转变到二分类  这个可以分成3种
1. 一对一(OVO)  做n*(n-1)/2次 每两个比一次 最终看哪个多
2. 一对多(OVR)  做n次 一个为正例 其他都为反例
3. 多对多(MVM) 
常用的是ECOC纠错输出码 对N个类做M次划分 做M个分类器  之后在进行解码 根据距离判断 编码越长能更好的纠错 若长度相同 那么任意两个类别越远越好

#### 3.6 类别不平衡问题
常用三种方法   
1. 欠采样 去除部分反例 时间开销小 可能丢失信息  EasyEnsemble
2. 过采样 增加部分正例 不能直接复制正例  SMOTE
3. 阈值移动  根据训练集正反例的比例移动阈值

# Chapter 4 决策树
#### 4.1 基本流程
存在3种特殊情况
1. 所有样本在同一类别  无须划分
2. 当前属性为空 或所有属性相同 无需划分 用当前父节点最多的样本
3. 当前节点包括样本数为空 不能划分 用当前福节点最多样本

#### 4.2 划分选择
信息熵: Ent(D) = sum(-pk \* log2 pk)  
信息增益: 判断是否要继续划分  Gain(D,a) = Ent(D) - sum(Dv/D * Ent(Dv)) Dv 是d的子类  
信息增益越大 那么用该属性作为划分选择效果最好  
ID3 就是用信息增益来作为划分属性

---

由于信息增益对取值数目较多的属性有所偏好  比如 一个属性分成17个 每个1个样本 那么它信息增益很大 但是不具有泛化能力 故信息增益在一定条件下不具有意义 故引入了增益率   
增益率: Gain_ratio(D,a) = Gain(D,a)/IV(a)  IV(a) = -sum(Dv/D * log2 (Dv/D))   
C4.5的算法就是用增益率  

---

基尼指数:Gini(D) = sum(sum(pk*pk')) = 1-sum(pk*pk)    (k'!=k)
基尼指数代表随机抽取两个样本  不一样的概率
Gini_index(D,a) = sum(Dv/D * Gini(Dv)) 选择基尼指数最小的
CART决策树用基尼指数

#### 4.3 剪枝处理
剪枝是防止过拟合 分为预剪枝和后剪枝
- 预剪枝: 在划分前判断是否增加了准确率  若不增加  那么就不继续进行新的划分 这能减少过拟合的风险  但是由于本质是放置分支展开  会有欠拟合的风险  
- 后剪枝: 从底部开始  判断将节点转为叶节点 看是否会增加正确率  
  欠拟合风险小  泛化能力由于预剪枝

#### 4.4 连续与缺失值
- 连续值处理 
  主要采用二分法 也是C4.5的算法中用的机制  
  将划分点设置成两个值的中点 然后分成左边和右边 可以多次分类
- 缺失值处理  
  将之前的Gain 和 Ent 公式改变   
  Gain(D,a) = p * Gain(D',a)  p= sum(D'/D) D'代表没有缺失的  
  Ent(D') = -sum(pk' * log2 pk')  pk'代表无缺失样本中k类的数目  
  判断时 若已知则直接按照已知的做  若未知 则将他划分如所有子类 并将权值改为已有的比例 最后可以看到概率

#### 4.5 多变量决策树
之前的决策树在判断的时候只有一个变量在判断  将它放入坐标系 坐标系代表变量 那么 都是平行坐标系的直线
多变量就是 将平行坐标系变成斜线 判断时候多个变量联合判断

